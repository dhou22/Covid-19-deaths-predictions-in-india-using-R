**commands for data cleaning***


# Load required libraries
library(tidyverse)
library(lubridate)
library(janitor)
library(naniar)
library(mice)

# Read the data (replace with your data source)
covid_data <- read.csv("covid_data.csv")

# Basic data cleaning steps
clean_covid_data <- covid_data %>%
  # Clean column names
  clean_names() %>%
  
  # Convert date column to proper format
  mutate(date = as.Date(date)) %>%
  
  # Remove duplicate rows
  distinct() %>%
  
  # Convert character columns to proper types
  mutate(across(where(is.character), as.factor)) %>%
  
  # Convert numeric columns with commas and percentages
  mutate(across(matches("rate|percentage"), 
                ~as.numeric(gsub("[%,]", "", .))))

# Handle missing values
missing_summary <- miss_var_summary(clean_covid_data)
print(missing_summary)

# Remove rows with high missing percentage
clean_covid_data <- clean_covid_data %>%
  filter(across(everything(), ~!is.na(.) | row_number() <= 5))

# Impute missing values using MICE
imputed_data <- mice(clean_covid_data, m=5, method='pmm', seed=123)
clean_covid_data <- complete(imputed_data)

# Handle outliers
clean_covid_data <- clean_covid_data %>%
  mutate(across(where(is.numeric), ~ifelse(
    . > quantile(., 0.975, na.rm = TRUE) |
    . < quantile(., 0.025, na.rm = TRUE),
    NA, .
  )))

# Create derived features
clean_covid_data <- clean_covid_data %>%
  group_by(region) %>%  # Assuming region exists
  mutate(
    cases_per_100k = (cases / population) * 100000,
    death_rate = (deaths / cases) * 100,
    cases_7day_avg = rollmean(cases, k = 7, fill = NA, align = "right"),
    deaths_7day_avg = rollmean(deaths, k = 7, fill = NA, align = "right"),
    cases_growth_rate = (cases - lag(cases)) / lag(cases) * 100
  ) %>%
  ungroup()

# Normalize numeric variables
clean_covid_data <- clean_covid_data %>%
  mutate(across(where(is.numeric), ~scale(.), .names = "{.col}_normalized"))

# Check for correlations
correlation_matrix <- cor(select_if(clean_covid_data, is.numeric), 
                         use = "complete.obs")
print(correlation_matrix)

# Save cleaned data
write.csv(clean_covid_data, "cleaned_covid_data.csv", row.names = FALSE)

# Data quality report
data_report <- list(
  missing_values = miss_var_summary(clean_covid_data),
  column_types = sapply(clean_covid_data, class),
  unique_values = sapply(clean_covid_data, n_distinct),
  summary_stats = summary(clean_covid_data)
)

print(data_report)

# Function to detect anomalies
detect_anomalies <- function(x) {
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  q3 <- quantile(x, 0.75, na.rm = TRUE)
  iqr <- q3 - q1
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 1.5 * iqr
  return(x < lower_bound | x > upper_bound)
}

# Apply anomaly detection
numeric_cols <- names(select_if(clean_covid_data, is.numeric))
for(col in numeric_cols) {
  clean_covid_data[[paste0(col, "_anomaly")]] <- 
    detect_anomalies(clean_covid_data[[col]])
}